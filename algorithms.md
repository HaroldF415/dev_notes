# Algorithms

There is a book I bought years ago when I was first starting to learn COMP SCI. Eveytime I would start it I would give up before reaching the 2nd chapter. This time around I will do better.

_Book_

Name: Introduction to Algorithms [3rd Edition]
Authors: Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein.

## Foundations

### "We should consider algorithms as a technology."

Just reading the introduction to this book I'm hit with a barrage of information that almost makes no sense to me. But I will write them down in this markdown file and find out what it all means.

Algorithms in this book will be presented in "pseudocode". For clarity's sake let's define these vocabulary terms:

Algorithm: a list of well-defined steps that provide instructions on how to accomplish a specific task.

Pseudocode: a way to express the logic of an algorithm in a more human-readable and informal manner.

Pseudocode serves as an intermediate step between a high-level description of an algorithm and actual code written in a specific programming language.

There are different kinds of algorithms most importantly sorting algorithms.

Insertion Sort - uses an incremental approach.
Merge Sort - uses recursive technique [ divide and conquer ]

The time each sorting algorithm requires increases with the value of _n_ [ the rate of increase between the two algorithms. ]

In order to express this "asymptotic notation" is used.

Asymptotic Notation: [ Big O Notation ] - is a mathematical notation used in computer science and software engineering to analyze and describe the performance or efficiency of algorithms. It provides a way to express the upper bound or worst-case behavior of an algorithm's runtime or space complexity in terms of its input size.

Methods for solving recurrences: useful for describing the running times of recursive algorithms.

Recursive Algorithms: they are algorithms that solve problems by breaking them down into smaller, self-similar subproblems of the same type.

A powerful technique for describing the running times of recursive methods are "Master Methods".

Master Method/Theorem: is a mathematical tool used for analyzing the time complexity of divide-and conquer algorithms. It provides a way to determine the time complexity of such algorithms by solving recurrence relations that describe the algorithm's behavior.

Probabilistic Analysis and Randomized Algorithms.

Probabilistic Analysis: allows researchers and practioners to account for uncertainty and randomness in their analysis, leading to more realistic assessments of algorithm or system performance in the real-world.

Probability Distribution:
